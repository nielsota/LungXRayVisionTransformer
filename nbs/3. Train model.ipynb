{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5149a11f",
   "metadata": {},
   "source": [
    "# Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8da01502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pathlib\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc350b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'models'\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXPORTS_DIR = DATA_DIR / 'exports'\n",
    "XRAY_LUNG_CLF_DIR = DATA_DIR / 'xray_lung_clf'\n",
    "\n",
    "TRAIN_DATA_PATH = XRAY_LUNG_CLF_DIR / 'train'\n",
    "TEST_DATA_PATH = XRAY_LUNG_CLF_DIR / 'test'\n",
    "\n",
    "TRAIN_ANNOTATIONS_PATH = XRAY_LUNG_CLF_DIR / 'train_annotations.json'\n",
    "TEST_ANNOTATIONS_PATH = XRAY_LUNG_CLF_DIR / 'test_annotations.json'\n",
    "\n",
    "EXPORTS_LUNG_CLF_DIR = EXPORTS_DIR / 'xray_lung_clf'\n",
    "\n",
    "serve_pytorch_dir = BASE_DIR / 'serve_pytorch'\n",
    "train_py_path = serve_pytorch_dir / 'train.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98ed80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# Get Role\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Get Bucket\n",
    "bucket = boto3.resource('s3').Bucket('lung-xray-bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "265ea9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-906764816799/lung_data\n"
     ]
    }
   ],
   "source": [
    "# Get data dir\n",
    "#data_dir = str(EXPORTS_LUNG_CLF_DIR)\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "#prefix = 'lung_data'\n",
    "\n",
    "# upload all data to S3\n",
    "#input_data = session.upload_data(data_dir, bucket=bucket, key_prefix=prefix)\n",
    "#print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24d388e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/test_X.z\n",
      "data/test_Y.z\n",
      "data/train_X.z\n",
      "data/train_Y.z\n"
     ]
    }
   ],
   "source": [
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53682d",
   "metadata": {},
   "source": [
    "# Create PyTorch esitmator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a05012",
   "metadata": {},
   "source": [
    "Debugging learned:\n",
    "- need to install some packages on remote EC2 for training job -> put requirements.txt in same folder as train.py and model.py\n",
    "- data needs to be stored in same region as sagemaker notebook instance\n",
    "- creating a notebook instance in one region means it will not be visible from another\n",
    "- the blue printing message lists al the SM_* enviroment variables, when prompted with a KeyError, check if key is present. Example: Needed to change SM_CHANNEL_TRAIN to SM_CHANNEL_TRAINING.\n",
    "- valid loss increase after 84 epochs\n",
    "- BLEWITHLOGISTLOSS combines sigmoid and BCE in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f31435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from source: s3://lung-xray-bucket/data\n"
     ]
    }
   ],
   "source": [
    "prefix = 'data'\n",
    "\n",
    "bucket_name = str(bucket.name)\n",
    "\n",
    "input_data = f's3://{bucket_name}/{prefix}'\n",
    "\n",
    "print(f'Downloading data from source: {input_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b010e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 12:56:27 Starting - Starting the training job...\n",
      "2021-12-10 12:56:29 Starting - Launching requested ML instancesProfilerReport-1639140987: InProgress\n",
      "......\n",
      "2021-12-10 12:57:56 Starting - Preparing the instances for training.........\n",
      "2021-12-10 12:59:20 Downloading - Downloading input data\n",
      "2021-12-10 12:59:20 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:34,309 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:34,311 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:34,319 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:34,939 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:35,195 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.9.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting einops\n",
      "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (4.59.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.0)\u001b[0m\n",
      "\u001b[34mCollecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (2.30.0)\u001b[0m\n",
      "\u001b[34mCollecting datetime\n",
      "  Downloading DateTime-4.3-py2.py3-none-any.whl (60 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zope.interface in /opt/conda/lib/python3.6/site-packages (from datetime->-r requirements.txt (line 14)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from datetime->-r requirements.txt (line 14)) (2021.1)\u001b[0m\n",
      "\u001b[34mCollecting ipykernel\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\u001b[0m\n",
      "\u001b[34mCollecting qtconsole\n",
      "  Downloading qtconsole-5.2.1-py3-none-any.whl (120 kB)\u001b[0m\n",
      "\u001b[34mCollecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\u001b[0m\n",
      "\u001b[34mCollecting notebook\n",
      "  Downloading notebook-6.4.6-py3-none-any.whl (9.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting nbconvert\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 4)) (7.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 4)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (3.15.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (20.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (3.7.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.16.32 in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (1.17.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.6/site-packages (from sagemaker->-r requirements.txt (line 13)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.30 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker->-r requirements.txt (line 13)) (1.20.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker->-r requirements.txt (line 13)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker->-r requirements.txt (line 13)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.30->boto3>=1.16.32->sagemaker->-r requirements.txt (line 13)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker->-r requirements.txt (line 13)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker->-r requirements.txt (line 13)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 11)) (0.24.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 7)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 7)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 7)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 7)) (2.25.1)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.42.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (4.5)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=1.4.0\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2.10)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (7.16.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (4.3.3)\u001b[0m\n",
      "\u001b[34mCollecting tornado>=4.2\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-client\n",
      "  Downloading jupyter_client-7.1.0-py3-none-any.whl (129 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (2.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (3.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (4.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 3)) (0.2.5)\u001b[0m\n",
      "\u001b[34mCollecting nbformat>=4.2.0\n",
      "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\u001b[0m\n",
      "\u001b[34mCollecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema!=2.5.0,>=2.4\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-core\n",
      "  Downloading jupyter_core-4.9.1-py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-client\n",
      "  Downloading prometheus_client-0.12.0-py2.py3-none-any.whl (57 kB)\u001b[0m\n",
      "\u001b[34mCollecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.2.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting nest-asyncio>=1.5\n",
      "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyzmq>=17\n",
      "  Downloading pyzmq-22.3.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting terminado>=0.8.3\n",
      "  Downloading terminado-0.12.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->-r requirements.txt (line 3)) (2.11.3)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 3)) (0.6.0)\u001b[0m\n",
      "\u001b[34mCollecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 3)) (1.14.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 3)) (2.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 3)) (1.1.1)\u001b[0m\n",
      "\u001b[34mCollecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.9-py3-none-any.whl (69 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting testpath\n",
      "  Downloading testpath-0.5.0-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34mCollecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting bleach\n",
      "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\u001b[0m\n",
      "\u001b[34mCollecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting qtpy\n",
      "  Downloading QtPy-1.11.3-py2.py3-none-any.whl (59 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 11)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 11)) (2.1.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyrsistent, importlib-metadata, tornado, pyzmq, nest-asyncio, jupyter-core, jsonschema, entrypoints, webencodings, nbformat, jupyter-client, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, ipykernel, argon2-cffi, pyasn1-modules, oauthlib, notebook, cachetools, widgetsnbextension, requests-oauthlib, qtpy, jupyterlab-widgets, google-auth, tensorboard-plugin-wit, tensorboard-data-server, qtconsole, markdown, jupyter-console, ipywidgets, grpcio, google-auth-oauthlib, absl-py, tensorboard, jupyter, einops, datetime, argparse\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.3\n",
      "    Uninstalling importlib-metadata-3.7.3:\n",
      "      Successfully uninstalled importlib-metadata-3.7.3\u001b[0m\n",
      "\n",
      "2021-12-10 12:59:57 Training - Training image download completed. Training in progress.\u001b[34mSuccessfully installed Send2Trash-1.8.0 absl-py-1.0.0 argon2-cffi-21.2.0 argon2-cffi-bindings-21.2.0 argparse-1.4.0 async-generator-1.10 bleach-4.1.0 cachetools-4.2.4 datetime-4.3 defusedxml-0.7.1 einops-0.3.2 entrypoints-0.3 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.42.0 importlib-metadata-4.8.2 ipykernel-5.5.6 ipywidgets-7.6.5 jsonschema-3.2.0 jupyter-1.0.0 jupyter-client-7.1.0 jupyter-console-6.4.0 jupyter-core-4.9.1 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.2 markdown-3.3.6 mistune-0.8.4 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 nest-asyncio-1.5.4 notebook-6.4.6 oauthlib-3.1.1 pandocfilters-1.5.0 prometheus-client-0.12.0 pyasn1-modules-0.2.8 pyrsistent-0.18.0 pyzmq-22.3.0 qtconsole-5.2.1 qtpy-1.11.3 requests-oauthlib-1.3.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 terminado-0.12.1 testpath-0.5.0 tornado-6.1 webencodings-0.5.1 widgetsnbextension-3.5.2\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:46,293 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:46,304 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:46,315 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-10 12:59:46,324 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-12-10-12-56-27-587\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-841835632701/pytorch-training-2021-12-10-12-56-27-587/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-841835632701/pytorch-training-2021-12-10-12-56-27-587/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-12-10-12-56-27-587\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-841835632701/pytorch-training-2021-12-10-12-56-27-587/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mGet train data and valid data loaders.\u001b[0m\n",
      "\u001b[34mstarting training.\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.643 algo-1:34 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.818 algo-1:34 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.818 algo-1:34 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.819 algo-1:34 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.819 algo-1:34 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.819 algo-1:34 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:cls_token count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:pos_embedding count_params:4160\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:patch_to_embedding.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:patch_to_embedding.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.attention.toqueries.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.attention.tokeys.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.attention.tovalues.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.attention.unifyheads.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.attention.unifyheads.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.norm1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.norm1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.827 algo-1:34 INFO hook.py:584] name:transformer.ff.0.norm2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.0.norm2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.0.mlp.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.0.mlp.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.0.mlp.2.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.0.mlp.2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.attention.toqueries.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.attention.tokeys.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.attention.tovalues.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.attention.unifyheads.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.attention.unifyheads.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.norm1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.norm1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.norm2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.norm2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.mlp.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.mlp.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.mlp.2.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.828 algo-1:34 INFO hook.py:584] name:transformer.ff.1.mlp.2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.attention.toqueries.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.attention.tokeys.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.attention.tovalues.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.attention.unifyheads.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.attention.unifyheads.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.norm1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.norm1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.norm2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.norm2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.mlp.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.mlp.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.mlp.2.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:transformer.ff.2.mlp.2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:mlp_head.0.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:mlp_head.0.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:mlp_head.2.weight count_params:832\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:584] name:mlp_head.2.bias count_params:13\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:586] Total Trainable Params: 568269\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.829 algo-1:34 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.832 algo-1:34 INFO hook.py:476] Hook is writing from the hook with pid: 34\u001b[0m\n",
      "\u001b[34m[2021-12-10 12:59:50.837 algo-1:34 WARNING hook.py:1037] var is not Tensor or list or tuple of Tensors, module_name:rearrange_layer int\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.6087043166160584, Valid Loss: 0.5664549310540044\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5477715849876403, Valid Loss: 0.5280228402725485\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.519092532992363, Valid Loss: 0.5082282444765401\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.5034878194332123, Valid Loss: 0.4953565715357315\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.49160718023777006, Valid Loss: 0.48394444030384687\u001b[0m\n",
      "\u001b[34m[2021-12-10 13:00:13.882 algo-1:34 WARNING hook.py:1037] var is not Tensor or list or tuple of Tensors, module_name:rearrange_layer int\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.4804801195859909, Valid Loss: 0.4729194668836372\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.46963933408260344, Valid Loss: 0.4621396057827528\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.45902979373931885, Valid Loss: 0.4515776939170305\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.44865459501743316, Valid Loss: 0.44128837627033857\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.43858020603656767, Valid Loss: 0.43133626878261566\u001b[0m\n",
      "\u001b[34m[2021-12-10 13:00:35.304 algo-1:34 WARNING hook.py:1037] var is not Tensor or list or tuple of Tensors, module_name:rearrange_layer int\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.42887485325336455, Valid Loss: 0.42179898675097977\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.41961280405521395, Valid Loss: 0.41274766034858174\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.41085848212242126, Valid Loss: 0.4042477150296056\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.40267553627491, Valid Loss: 0.3963429813468179\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.3950955718755722, Valid Loss: 0.3890652552593586\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.3881407409906387, Valid Loss: 0.3824221342802048\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.3818097859621048, Valid Loss: 0.37640917509101157\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.3761033922433853, Valid Loss: 0.3710069226664166\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.3709843933582306, Valid Loss: 0.36617877594260284\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.366424897313118, Valid Loss: 0.361894054468288\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.3623804062604904, Valid Loss: 0.35810588057651077\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.35881619453430175, Valid Loss: 0.35477677611417546\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.3556807994842529, Valid Loss: 0.3518524502598962\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.35293238461017606, Valid Loss: 0.34929245155911115\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.35052274763584135, Valid Loss: 0.34705600142478943\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.34841508567333224, Valid Loss: 0.3451018589873647\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.3465703308582306, Valid Loss: 0.34339637985063154\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.344960144162178, Valid Loss: 0.3419081447429435\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.34355024695396424, Valid Loss: 0.34060887126035466\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.34231155216693876, Valid Loss: 0.33947322049806283\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.34122558534145353, Valid Loss: 0.33848195609658266\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.34027321040630343, Valid Loss: 0.33761111802833027\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.33943007290363314, Valid Loss: 0.33684907784295637\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.338689911365509, Valid Loss: 0.3361802797677905\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.3380310446023941, Valid Loss: 0.3355910507745521\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.3374470710754395, Valid Loss: 0.33507002300994343\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.33692510426044464, Valid Loss: 0.3346097469329834\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.33646360039711, Valid Loss: 0.3342012839261876\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.33604857325553894, Valid Loss: 0.33384081478728805\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.33567323088645934, Valid Loss: 0.3335190803505654\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.3353384345769882, Valid Loss: 0.3332324180492135\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.33503752648830415, Valid Loss: 0.33297761547011\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.334759983420372, Valid Loss: 0.33274569587652075\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.3345073193311691, Valid Loss: 0.332538096710693\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.33428198993206026, Valid Loss: 0.3323510535234629\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.3340654581785202, Valid Loss: 0.33218036488045094\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.3338644415140152, Valid Loss: 0.3320279963487803\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.33367822468280794, Valid Loss: 0.3318805701510851\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.33350315392017366, Valid Loss: 0.33175546381362647\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.3333293735980988, Valid Loss: 0.33163599046163783\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.3331701636314392, Valid Loss: 0.33152099993339806\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.33301196098327634, Valid Loss: 0.3314122443282327\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.33286077082157134, Valid Loss: 0.33131155926127764\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.33270521759986876, Valid Loss: 0.33121781051158905\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.3325462877750397, Valid Loss: 0.3311242655266163\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.3323867440223694, Valid Loss: 0.33103693917740223\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.33221973180770875, Valid Loss: 0.33096054716165674\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.3320439547300339, Valid Loss: 0.33088694928690443\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.3318534255027771, Valid Loss: 0.3308118020379266\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.33166212141513823, Valid Loss: 0.3307590269765189\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.3314438670873642, Valid Loss: 0.3306943937096485\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.3312164694070816, Valid Loss: 0.33063816573730737\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.33095869421958923, Valid Loss: 0.330578388516293\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.33069358170032503, Valid Loss: 0.33052157108173813\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.33040541112422944, Valid Loss: 0.330458911698918\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.33009135723114014, Valid Loss: 0.33038253562394965\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.3297437787055969, Valid Loss: 0.33030733119609745\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.32940598726272585, Valid Loss: 0.33021385274654214\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.3290029108524323, Valid Loss: 0.3301410730495009\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.3286108195781708, Valid Loss: 0.3300636171601539\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.328167924284935, Valid Loss: 0.3299549984377484\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.3276863366365433, Valid Loss: 0.3298620151918988\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.32720241248607634, Valid Loss: 0.3297620008504668\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.32668048739433286, Valid Loss: 0.32961767981218737\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.3260998994112015, Valid Loss: 0.32945652392714525\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.32545784711837766, Valid Loss: 0.329273012834926\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.3247563302516937, Valid Loss: 0.32906572364790493\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.3239692896604538, Valid Loss: 0.3288646979733955\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.3231322020292282, Valid Loss: 0.328659891908945\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.32222417891025545, Valid Loss: 0.3283887985487317\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.3211980938911438, Valid Loss: 0.3280993284181107\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.3200818657875061, Valid Loss: 0.32804523200489755\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.3189818233251572, Valid Loss: 0.3279751528834188\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.3176985889673233, Valid Loss: 0.32806136233862054\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 307, in <module>\n",
      "    model_fn(model_dir)\u001b[0m\n",
      "\u001b[34mNameError: name 'model_dir' is not defined\u001b[0m\n",
      "\u001b[34m2021-12-10 13:05:40,283 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.6 train.py\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 307, in <module>\n",
      "    model_fn(model_dir)\u001b[0m\n",
      "\u001b[34mNameError: name 'model_dir' is not defined\u001b[0m\n",
      "\n",
      "2021-12-10 13:06:00 Uploading - Uploading generated training model\n",
      "2021-12-10 13:06:00 Failed - Training job failed\n",
      "ProfilerReport-1639140987: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2021-12-10-12-56-27-587: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 train.py\"\nTraceback (most recent call last):\n  File \"train.py\", line 307, in <module>\n    model_fn(model_dir)\nNameError: name 'model_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c11842f8b812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     sagemaker_session = session)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3778\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3333\u001b[0m                 ),\n\u001b[1;32m   3334\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3335\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3336\u001b[0m             )\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2021-12-10-12-56-27-587: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 train.py\"\nTraceback (most recent call last):\n  File \"train.py\", line 307, in <module>\n    model_fn(model_dir)\nNameError: name 'model_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "                    entry_point = 'train.py',\n",
    "                    source_dir = str(serve_pytorch_dir),\n",
    "                    role = role,\n",
    "                    instance_count = 1,\n",
    "                    instance_type = 'ml.c5.xlarge',\n",
    "                    framework_version='1.8.0',\n",
    "                    py_version='py3',\n",
    "                    sagemaker_session = session)\n",
    "\n",
    "estimator.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f803d",
   "metadata": {},
   "source": [
    "# Deploy Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b227275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
