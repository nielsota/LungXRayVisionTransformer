{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import joblib\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "\n",
    "EXPORTS_DIR = DATA_DIR / 'exports'\n",
    "XRAY_LUNG_CLF_DIR = DATA_DIR / 'xray_lung_clf'\n",
    "\n",
    "TRAIN_DATA_PATH = XRAY_LUNG_CLF_DIR / 'train'\n",
    "TEST_DATA_PATH = XRAY_LUNG_CLF_DIR / 'test'\n",
    "\n",
    "TRAIN_ANNOTATIONS_PATH = XRAY_LUNG_CLF_DIR / 'train_annotations.json'\n",
    "TEST_ANNOTATIONS_PATH = XRAY_LUNG_CLF_DIR / 'test_annotations.json'\n",
    "\n",
    "EXPORTS_LUNGCLF_DIR = EXPORTS_DIR / 'xray_lung_clf'\n",
    "\n",
    "EXPORTS_TRAIN_DATA_PATH = EXPORTS_LUNGCLF_DIR / 'train_X.z'\n",
    "EXPORTS_TEST_DATA_PATH = EXPORTS_LUNGCLF_DIR / 'test_X.z'\n",
    "\n",
    "EXPORTS_TRAIN_LABELS_PATH = EXPORTS_LUNGCLF_DIR / 'train_Y.z'\n",
    "EXPORTS_TEST_LABELS_PATH = EXPORTS_LUNGCLF_DIR / 'test_Y.z'\n",
    "\n",
    "EXPORTS_LUNGCLF_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(nrows: int = 5, ncols: int = 5):\n",
    "    '''\n",
    "    loads matrix of sample images\n",
    "    '''\n",
    "    \n",
    "    # load all paths\n",
    "    all_paths = []\n",
    "    \n",
    "    for path in TRAIN_DATA_PATH.glob('*'):\n",
    "        all_paths.append(str(path))\n",
    "    \n",
    "    # select subsample of paths\n",
    "    img_paths = random.choices(all_paths, k=nrows * ncols)\n",
    "    \n",
    "    # create array of images\n",
    "    fig, axs = plt.subplots(nrows, ncols)\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            img_path = img_paths[i * nrows + j]\n",
    "            img = mpimg.imread(img_path)\n",
    "            axs[i, j].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matching_filenames(ANNOTATIONS_PATH, DATA_PATH):\n",
    "    '''\n",
    "    for given file paths, check if image and label file names match\n",
    "    '''\n",
    "    \n",
    "    # load and sort annotations\n",
    "    with open(str(ANNOTATIONS_PATH)) as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    annotations = sorted(annotations, key=lambda d: d['file_name']) \n",
    "    \n",
    "    # check that order in list of paths to images matches order in annotations file\n",
    "    all_paths = []\n",
    "    \n",
    "    for i, path in enumerate(sorted(DATA_PATH.glob('*.png'))):\n",
    "        all_paths.append(pathlib.Path(path))\n",
    "        try:\n",
    "            assert pathlib.Path(path).name == annotations[i]['file_name']\n",
    "        except:\n",
    "            print(f'No match of file names at index {i}')\n",
    "    \n",
    "    if DATA_PATH.name.startswith('train'):\n",
    "        data_type = 'train'\n",
    "    elif DATA_PATH.name.startswith('test'):\n",
    "        data_type = 'test'\n",
    "    else: \n",
    "        data_type = ''\n",
    "    \n",
    "    print(f'succesfully matched {data_type} data')\n",
    "        \n",
    "    return annotations, all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_tensor(paths):   \n",
    "    '''\n",
    "    Images in folder come in all shapes and sizes. Convert all into images w/ 1 channel. \n",
    "    '''\n",
    "\n",
    "    images_in_tensor = []\n",
    "\n",
    "    for i in tqdm(range(len(paths))):\n",
    "\n",
    "        # read into array\n",
    "        img = mpimg.imread(str(paths[i]))\n",
    "\n",
    "        # mean out different channels if C>1\n",
    "        try:\n",
    "            img = img.mean(axis=2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Read into tensors and add dummy channel C=1\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        img_tensor = img_tensor[None, :, :]\n",
    "\n",
    "        # Reshape\n",
    "        image_transformation = torchvision.transforms.Compose([torchvision.transforms.Resize((256,256))])\n",
    "        reshaped_img_tensor = image_transformation(img_tensor)\n",
    "\n",
    "        # Add to list\n",
    "        images_in_tensor.append(reshaped_img_tensor)\n",
    "\n",
    "    # stack along new dimension, cat along existing dimension\n",
    "    data_tensor = torch.stack(images_in_tensor, dim = 0)\n",
    "    \n",
    "    return data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diseases(annotations):\n",
    "    \n",
    "    '''\n",
    "    Find unique diseases.\n",
    "    '''\n",
    "\n",
    "    diseases = [ind['syms'] for ind in annotations]\n",
    "    flat_diseases = [item for sublist in diseases for item in sublist]\n",
    "    diseases = list(set(flat_diseases))\n",
    "    num_diseases = len(diseases)\n",
    "    \n",
    "    return num_diseases, diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot(annotations, encoder=None):\n",
    "    '''\n",
    "    Create OneHot vectors\n",
    "    '''\n",
    "    \n",
    "    y_onehot = []\n",
    "    num_diseases, diseases = count_diseases(annotations)\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(diseases)\n",
    "    \n",
    "    for ind in tqdm(annotations):\n",
    "        y = encoder.transform(ind['syms'])\n",
    "        y_onehot_list = [1 if i in y else 0 for i in range(num_diseases)]\n",
    "        y_onehot_tensor = torch.FloatTensor(y_onehot_list)\n",
    "        y_onehot.append(y_onehot_tensor)\n",
    "    \n",
    "    y = torch.stack(y_onehot, axis=0)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return y, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations, train_paths = check_matching_filenames(TRAIN_ANNOTATIONS_PATH, TRAIN_DATA_PATH)\n",
    "test_annotations, test_paths = check_matching_filenames(TEST_ANNOTATIONS_PATH, TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = create_image_tensor(train_paths)\n",
    "test_X = create_image_tensor(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y, encoder = create_one_hot(train_annotations, encoder=None)\n",
    "test_Y, _ = create_one_hot(test_annotations, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert train_X.shape[0] == train_Y.shape[0]\n",
    "assert train_X.shape[1] == test_X.shape[1]\n",
    "assert train_X.shape[2] == test_X.shape[2]\n",
    "assert train_X.shape[3] == test_X.shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print summary & save data (pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {train_X.shape[0]} training examples')\n",
    "print(f'There are {test_X.shape[0]} training examples')\n",
    "print(f'The images have {train_X.shape[1]} channels')\n",
    "print(f'The images are of size {train_X.shape[2]} x {train_X.shape[3]} channels')\n",
    "print(f'There are {train_Y.shape[1]} different diseases')\n",
    "print(f'shape of the data is: {train_X.shape}')\n",
    "print(f'type of the data is: {type(train_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORTS_TRAIN_DATA_PATH, 'wb') as f:\n",
    "    joblib.dump(train_X.numpy(), f)\n",
    "\n",
    "with open(EXPORTS_TEST_DATA_PATH, 'wb') as f:\n",
    "    joblib.dump(test_X.numpy(), f)\n",
    "\n",
    "with open(EXPORTS_TRAIN_LABELS_PATH, 'wb') as f:\n",
    "    joblib.dump(train_Y.numpy(), f)\n",
    "    \n",
    "with open(EXPORTS_TEST_LABELS_PATH, 'wb') as f:\n",
    "    joblib.dump(test_Y.numpy(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORTS_TRAIN_DATA_PATH, 'rb') as f:\n",
    "    X_train = joblib.load(f)\n",
    "\n",
    "with open(EXPORTS_TEST_DATA_PATH, 'rb') as f:\n",
    "    X_test = joblib.load(f)\n",
    "\n",
    "with open(EXPORTS_TRAIN_LABELS_PATH, 'rb') as f:\n",
    "    Y_train = joblib.load(f)\n",
    "    \n",
    "with open(EXPORTS_TEST_LABELS_PATH, 'rb') as f:\n",
    "    Y_test =joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape == train_X.shape\n",
    "assert X_test.shape == test_X.shape\n",
    "assert Y_train.shape == train_Y.shape\n",
    "assert Y_test.shape == test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "session = boto3.session.Session()\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "BUCKET_NAME = 'lung-xray'\n",
    "\n",
    "bucket = s3.create_bucket(Bucket = BUCKET_NAME)\n",
    "\n",
    "for path in EXPORTS_LUNGCLF_DIR.glob('*'):\n",
    "    bucket.upload_file(Filename=str(path), Key=path.name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
